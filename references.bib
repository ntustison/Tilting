% This file was created with JabRef 2.8.1.
% Encoding: ISO8859_1

@ARTICLE{aguirre2012,
  author = {Aguirre, Geoffrey K},
  title = {{FIASCO}, {VoxBo}, and {MEDx}: behind the code},
  journal = {Neuroimage},
  year = {2012},
  volume = {62},
  pages = {765-7},
  number = {2},
  month = {Aug},
  abstract = {The early years of BOLD fMRI coincided with the rapid growth of both
	the internet and the open-source software movement. This environment
	encouraged the creation and dissemination of many neuroimaging software
	projects, only some of which survived. I tell the story of two of
	these open-source projects, FIASCO and VoxBo, as well as the interesting
	links between the commercial MedX software deployed at the NIH and
	satellite reconnaissance.},
  bdsk-url-1 = {http://dx.doi.org/10.1016/j.neuroimage.2012.02.003},
  date-added = {2013-05-06 16:01:21 +0000},
  date-modified = {2013-05-14 14:15:26 +0000},
  doi = {10.1016/j.neuroimage.2012.02.003},
  journal-full = {NeuroImage},
  mesh = {Brain; History, 20th Century; History, 21st Century; Humans; Image
	Processing, Computer-Assisted; Magnetic Resonance Imaging; Military
	Science; Software},
  pmid = {22348882},
  pst = {ppublish}
}

@ARTICLE{nature2007,
  author = {Anonymous},
  title = {Who is accountable?},
  journal = {Nature},
  year = {2007},
  volume = {450},
  pages = {1},
  number = {7166},
  month = {Nov},
  bdsk-url-1 = {http://dx.doi.org/10.1038/450001a},
  date-added = {2013-05-11 19:45:02 +0000},
  date-modified = {2013-05-14 13:37:00 +0000},
  doi = {10.1038/450001a},
  journal-full = {Nature},
  mesh = {Authorship; Periodicals as Topic; Research Personnel; Scientific
	Misconduct},
  pmid = {17972835},
  pst = {ppublish}
}

@ARTICLE{ashburner2012,
  author = {Ashburner, John},
  title = {{SPM}: a history},
  journal = {Neuroimage},
  year = {2012},
  volume = {62},
  pages = {791-800},
  number = {2},
  month = {Aug},
  abstract = {Karl Friston began the SPM project around 1991. The rest is history.},
  bdsk-url-1 = {http://dx.doi.org/10.1016/j.neuroimage.2011.10.025},
  date-added = {2013-05-06 15:59:43 +0000},
  date-modified = {2013-05-14 14:15:33 +0000},
  doi = {10.1016/j.neuroimage.2011.10.025},
  journal-full = {NeuroImage},
  mesh = {Brain; Brain Mapping; History, 20th Century; History, 21st Century;
	Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging;
	Software},
  pmc = {PMC3480642},
  pmid = {22023741},
  pst = {ppublish}
}

@ARTICLE{avants2011,
  author = {Avants, Brian B and Tustison, Nicholas J and Song, Gang and Cook,
	Philip A and Klein, Arno and Gee, James C},
  title = {A reproducible evaluation of {ANTs} similarity metric performance
	in brain image registration},
  journal = {Neuroimage},
  year = {2011},
  volume = {54},
  pages = {2033-44},
  number = {3},
  month = {Feb},
  abstract = {The United States National Institutes of Health (NIH) commit significant
	support to open-source data and software resources in order to foment
	reproducibility in the biomedical imaging sciences. Here, we report
	and evaluate a recent product of this commitment: Advanced Neuroimaging
	Tools (ANTs), which is approaching its 2.0 release. The ANTs open
	source software library consists of a suite of state-of-the-art image
	registration, segmentation and template building tools for quantitative
	morphometric analysis. In this work, we use ANTs to quantify, for
	the first time, the impact of similarity metrics on the affine and
	deformable components of a template-based normalization study. We
	detail the ANTs implementation of three similarity metrics: squared
	intensity difference, a new and faster cross-correlation, and voxel-wise
	mutual information. We then use two-fold cross-validation to compare
	their performance on openly available, manually labeled, T1-weighted
	MRI brain image data of 40 subjects (UCLA's LPBA40 dataset). We report
	evaluation results on cortical and whole brain labels for both the
	affine and deformable components of the registration. Results indicate
	that the best ANTs methods are competitive with existing brain extraction
	results (Jaccard=0.958) and cortical labeling approaches. Mutual
	information affine mapping combined with cross-correlation diffeomorphic
	mapping gave the best cortical labeling results (Jaccard=0.669$\pm$0.022).
	Furthermore, our two-fold cross-validation allows us to quantify
	the similarity of templates derived from different subgroups. Our
	open code, data and evaluation scripts set performance benchmark
	parameters for this state-of-the-art toolkit. This is the first study
	to use a consistent transformation framework to provide a reproducible
	evaluation of the isolated effect of the similarity metric on optimal
	template construction and brain labeling.},
  bdsk-url-1 = {http://dx.doi.org/10.1016/j.neuroimage.2010.09.025},
  date-added = {2013-05-09 00:22:54 +0000},
  date-modified = {2013-05-14 14:15:40 +0000},
  doi = {10.1016/j.neuroimage.2010.09.025},
  journal-full = {NeuroImage},
  mesh = {Algorithms; Brain; Databases, Factual; Diagnostic Imaging; Head;
	Humans; Image Processing, Computer-Assisted; Linear Models; Models,
	Anatomic; Models, Neurological; Population; Reproducibility of Results;
	Software},
  pmc = {PMC3065962},
  pmid = {20851191},
  pst = {ppublish}
}

@INPROCEEDINGS{avants2012,
  author = {Brian B. Avants and Nicholas J. Tustison and Gang Song and Baohua
	Wu and Michael Stauffer and Matthew McCormick and Hans J. Johnson
	and James C. Gee},
  title = {A Unified Image Registration Framework for {ITK}},
  booktitle = {WBIR},
  year = {2012},
  pages = {266-275},
  bdsk-url-1 = {http://dx.doi.org/10.1007/978-3-642-31340-0_28},
  date-added = {2013-05-09 17:39:45 +0000},
  date-modified = {2013-05-14 14:15:08 +0000}
}

@ARTICLE{Avants2010,
  author = {Avants, Brian B. and Yushkevich, Paul and Pluta, John and Minkoff,
	David and Korczykowski, Marc and Detre, John and Gee, James C.},
  title = {The optimal template effect in hippocampus studies of diseased populations.},
  journal = {Neuroimage},
  year = {2010},
  volume = {49},
  pages = {2457--2466},
  number = {3},
  month = {Feb},
  abstract = {We evaluate the impact of template choice on template-based segmentation
	of the hippocampus in epilepsy. Four dataset-specific strategies
	are quantitatively contrasted: the "closest to average" individual
	template, the average shape version of the closest to average template,
	a best appearance template and the best appearance and shape template
	proposed here and implemented in the open source toolkit Advanced
	Normalization Tools (ANTS). The cross-correlation similarity metric
	drives the correspondence model and is used consistently to determine
	the optimal appearance. Minimum shape distance in the diffeomorphic
	space determines optimal shape. Our evaluation results show that,
	with respect to gold-standard manual labeling of hippocampi in epilepsy,
	optimal shape and appearance template construction outperforms the
	other strategies for gaining data-derived templates. Our results
	also show the improvement is most significant on the diseased side
	and insignificant on the healthy side. Thus, the importance of the
	template increases when used to study pathology and may be less critical
	for normal control studies. Furthermore, explicit geometric optimization
	of the shape component of the unbiased template positively impacts
	the study of diseased hippocampi.},
  doi = {10.1016/j.neuroimage.2009.09.062},
  institution = {Department of Radiology, University of Pennsylvania, Philadelphia,
	PA 19104, USA. avants@grasp.cis.upenn.edu},
  keywords = {Algorithms; Atlases as Topic; Epilepsy, pathology; Hippocampus, pathology;
	Humans; Image Interpretation, Computer-Assisted},
  language = {eng},
  medline-pst = {ppublish},
  owner = {stnava},
  pii = {S1053-8119(09)01061-1},
  pmid = {19818860},
  timestamp = {2013.06.10},
  url = {http://dx.doi.org/10.1016/j.neuroimage.2009.09.062}
}

@ARTICLE{clarkson2011,
  author = {Clarkson, Matthew J and Cardoso, M Jorge and Ridgway, Gerard R and
	Modat, Marc and Leung, Kelvin K and Rohrer, Jonathan D and Fox, Nick
	C and Ourselin, S{\'e}bastien},
  title = {A comparison of voxel and surface based cortical thickness estimation
	methods},
  journal = {Neuroimage},
  year = {2011},
  volume = {57},
  pages = {856-65},
  number = {3},
  month = {Aug},
  abstract = {Cortical thickness estimation performed in-vivo via magnetic resonance
	imaging is an important technique for the diagnosis and understanding
	of the progression of neurodegenerative diseases. Currently, two
	different computational paradigms exist, with methods generally classified
	as either surface or voxel-based. This paper provides a much needed
	comparison of the surface-based method FreeSurfer and two voxel-based
	methods using clinical data. We test the effects of computing regional
	statistics using two different atlases and demonstrate that this
	makes a significant difference to the cortical thickness results.
	We assess reproducibility, and show that FreeSurfer has a regional
	standard deviation of thickness difference on same day scans that
	is significantly lower than either a Laplacian or Registration based
	method and discuss the trade off between reproducibility and segmentation
	accuracy caused by bending energy constraints. We demonstrate that
	voxel-based methods can detect similar patterns of group-wise differences
	as well as FreeSurfer in typical applications such as producing group-wise
	maps of statistically significant thickness change, but that regional
	statistics can vary between methods. We use a Support Vector Machine
	to classify patients against controls and did not find statistically
	significantly different results with voxel based methods compared
	to FreeSurfer. Finally we assessed longitudinal performance and concluded
	that currently FreeSurfer provides the most plausible measure of
	change over time, with further work required for voxel based methods.},
  bdsk-url-1 = {http://dx.doi.org/10.1016/j.neuroimage.2011.05.053},
  date-added = {2013-05-02 16:59:45 +0000},
  date-modified = {2013-05-02 16:59:45 +0000},
  doi = {10.1016/j.neuroimage.2011.05.053},
  journal-full = {NeuroImage},
  mesh = {Aged; Alzheimer Disease; Brain; Brain Mapping; Female; Frontotemporal
	Dementia; Humans; Image Interpretation, Computer-Assisted; Magnetic
	Resonance Imaging; Male; Reproducibility of Results},
  pmid = {21640841},
  pst = {ppublish}
}

@ARTICLE{cox2012,
  author = {Cox, Robert W},
  title = {{AFNI}: what a long strange trip it's been},
  journal = {Neuroimage},
  year = {2012},
  volume = {62},
  pages = {743-7},
  number = {2},
  month = {Aug},
  abstract = {AFNI is an open source software package for the analysis and display
	of functional MRI data. It originated in 1994 to meet the specific
	needs of researchers at the Medical College of Wisconsin, in particular
	the mapping of activation maps to Talairach-Tournoux space, but has
	been expanded steadily since then into a wide-ranging set of tool
	for FMRI data analyses. AFNI was the first platform for real-time
	3D functional activation and registration calculations. One of AFNI's
	main strengths is its flexibility and transparency. In recent years,
	significant efforts have been made to increase the user-friendliness
	of AFNI's FMRI processing stream, with the introduction of "super-scripts"
	to setup the entire analysis, and graphical front-ends for these
	managers.},
  bdsk-url-1 = {http://dx.doi.org/10.1016/j.neuroimage.2011.08.056},
  date-added = {2013-05-06 16:01:00 +0000},
  date-modified = {2013-05-14 14:15:48 +0000},
  doi = {10.1016/j.neuroimage.2011.08.056},
  journal-full = {NeuroImage},
  mesh = {Brain; History, 20th Century; History, 21st Century; Humans; Image
	Processing, Computer-Assisted; Magnetic Resonance Imaging; Software},
  pmc = {PMC3246532},
  pmid = {21889996},
  pst = {ppublish}
}

@ARTICLE{eskildsen2012,
  author = {Eskildsen, Simon F and Coup{\'e}, Pierrick and Fonov, Vladimir and
	Manj{\'o}n, Jos{\'e} V and Leung, Kelvin K and Guizard, Nicolas and
	Wassef, Shafik N and {\O}stergaard, Lasse Riis and Collins, D Louis
	and {Alzheimer's Disease Neuroimaging Initiative}},
  title = {BEaST: brain extraction based on nonlocal segmentation technique},
  journal = {Neuroimage},
  year = {2012},
  volume = {59},
  pages = {2362-73},
  number = {3},
  month = {Feb},
  abstract = {Brain extraction is an important step in the analysis of brain images.
	The variability in brain morphology and the difference in intensity
	characteristics due to imaging sequences make the development of
	a general purpose brain extraction algorithm challenging. To address
	this issue, we propose a new robust method (BEaST) dedicated to produce
	consistent and accurate brain extraction. This method is based on
	nonlocal segmentation embedded in a multi-resolution framework. A
	library of 80 priors is semi-automatically constructed from the NIH-sponsored
	MRI study of normal brain development, the International Consortium
	for Brain Mapping, and the Alzheimer's Disease Neuroimaging Initiative
	databases. In testing, a mean Dice similarity coefficient of 0.9834$\pm$0.0053
	was obtained when performing leave-one-out cross validation selecting
	only 20 priors from the library. Validation using the online Segmentation
	Validation Engine resulted in a top ranking position with a mean
	Dice coefficient of 0.9781$\pm$0.0047. Robustness of BEaST is demonstrated
	on all baseline ADNI data, resulting in a very low failure rate.
	The segmentation accuracy of the method is better than two widely
	used publicly available methods and recent state-of-the-art hybrid
	approaches. BEaST provides results comparable to a recent label fusion
	approach, while being 40 times faster and requiring a much smaller
	library of priors.},
  bdsk-url-1 = {http://dx.doi.org/10.1016/j.neuroimage.2011.09.012},
  date-added = {2013-05-29 00:34:09 +0000},
  date-modified = {2013-05-29 00:34:09 +0000},
  doi = {10.1016/j.neuroimage.2011.09.012},
  journal-full = {NeuroImage},
  mesh = {Adolescent; Adult; Algorithms; Brain; Brain Mapping; Computers; Databases,
	Factual; False Negative Reactions; False Positive Reactions; Female;
	Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging;
	Male; Quality Control; Reference Standards; Reproducibility of Results;
	Software; Young Adult},
  pmid = {21945694},
  pst = {ppublish}
}

@ARTICLE{fedorov2012,
  author = {Fedorov, Andriy and Beichel, Reinhard and Kalpathy-Cramer, Jayashree
	and Finet, Julien and Fillion-Robin, Jean-Christophe and Pujol, Sonia
	and Bauer, Christian and Jennings, Dominique and Fennessy, Fiona
	and Sonka, Milan and Buatti, John and Aylward, Stephen and Miller,
	James V and Pieper, Steve and Kikinis, Ron},
  title = {3D Slicer as an image computing platform for the Quantitative Imaging
	Network},
  journal = {Magn Reson Imaging},
  year = {2012},
  volume = {30},
  pages = {1323-41},
  number = {9},
  month = {Nov},
  abstract = {Quantitative analysis has tremendous but mostly unrealized potential
	in healthcare to support objective and accurate interpretation of
	the clinical imaging. In 2008, the National Cancer Institute began
	building the Quantitative Imaging Network (QIN) initiative with the
	goal of advancing quantitative imaging in the context of personalized
	therapy and evaluation of treatment response. Computerized analysis
	is an important component contributing to reproducibility and efficiency
	of the quantitative imaging techniques. The success of quantitative
	imaging is contingent on robust analysis methods and software tools
	to bring these methods from bench to bedside. 3D Slicer is a free
	open-source software application for medical image computing. As
	a clinical research tool, 3D Slicer is similar to a radiology workstation
	that supports versatile visualizations but also provides advanced
	functionality such as automated segmentation and registration for
	a variety of application domains. Unlike a typical radiology workstation,
	3D Slicer is free and is not tied to specific hardware. As a programming
	platform, 3D Slicer facilitates translation and evaluation of the
	new quantitative methods by allowing the biomedical researcher to
	focus on the implementation of the algorithm and providing abstractions
	for the common tasks of data communication, visualization and user
	interface development. Compared to other tools that provide aspects
	of this functionality, 3D Slicer is fully open source and can be
	readily extended and redistributed. In addition, 3D Slicer is designed
	to facilitate the development of new functionality in the form of
	3D Slicer extensions. In this paper, we present an overview of 3D
	Slicer as a platform for prototyping, development and evaluation
	of image analysis tools for clinical research applications. To illustrate
	the utility of the platform in the scope of QIN, we discuss several
	use cases of 3D Slicer by the existing QIN teams, and we elaborate
	on the future directions that can further facilitate development
	and validation of imaging biomarkers using 3D Slicer.},
  bdsk-url-1 = {http://dx.doi.org/10.1016/j.mri.2012.05.001},
  date-added = {2013-05-23 22:59:57 +0000},
  date-modified = {2013-05-23 22:59:57 +0000},
  doi = {10.1016/j.mri.2012.05.001},
  journal-full = {Magnetic resonance imaging},
  mesh = {Automation; Biological Markers; Brain Neoplasms; Databases, Factual;
	Diagnostic Imaging; Glioblastoma; Head and Neck Neoplasms; Humans;
	Imaging, Three-Dimensional; Magnetic Resonance Imaging; Male; Medical
	Informatics; Positron-Emission Tomography; Prostatic Neoplasms; Software;
	Tomography, X-Ray Computed},
  pmc = {PMC3466397},
  pmid = {22770690},
  pst = {ppublish}
}

@ARTICLE{fischl2012,
  author = {Fischl, Bruce},
  title = {{FreeSurfer}},
  journal = {Neuroimage},
  year = {2012},
  volume = {62},
  pages = {774-81},
  number = {2},
  month = {Aug},
  abstract = {FreeSurfer is a suite of tools for the analysis of neuroimaging data
	that provides an array of algorithms to quantify the functional,
	connectional and structural properties of the human brain. It has
	evolved from a package primarily aimed at generating surface representations
	of the cerebral cortex into one that automatically creates models
	of most macroscopically visible structures in the human brain given
	any reasonable T1-weighted input image. It is freely available, runs
	on a wide variety of hardware and software platforms, and is open
	source.},
  bdsk-url-1 = {http://dx.doi.org/10.1016/j.neuroimage.2012.01.021},
  date-added = {2013-05-06 16:00:15 +0000},
  date-modified = {2013-05-14 14:15:56 +0000},
  doi = {10.1016/j.neuroimage.2012.01.021},
  journal-full = {NeuroImage},
  mesh = {Algorithms; Brain; Brain Mapping; History, 20th Century; History,
	21st Century; Humans; Image Processing, Computer-Assisted; Magnetic
	Resonance Imaging; Software},
  pmid = {22248573},
  pst = {ppublish}
}

@ARTICLE{Fischl2012,
  author = {Fischl, Bruce},
  title = {FreeSurfer.},
  journal = {Neuroimage},
  year = {2012},
  volume = {62},
  pages = {774--781},
  number = {2},
  month = {Aug},
  abstract = {FreeSurfer is a suite of tools for the analysis of neuroimaging data
	that provides an array of algorithms to quantify the functional,
	connectional and structural properties of the human brain. It has
	evolved from a package primarily aimed at generating surface representations
	of the cerebral cortex into one that automatically creates models
	of most macroscopically visible structures in the human brain given
	any reasonable T1-weighted input image. It is freely available, runs
	on a wide variety of hardware and software platforms, and is open
	source.},
  doi = {10.1016/j.neuroimage.2012.01.021},
  institution = {Athinoula A Martinos Center, Dept. of Radiology, MGH, Harvard Medical
	School, MA fischl@nmr.mgh.harvard.edu, USA. fischl@nmr.mgh.harvard.edu},
  keywords = {Algorithms; Brain Mapping, history/methods; Brain, anatomy /\&/ histology;
	History, 20th Century; History, 21st Century; Humans; Image Processing,
	Computer-Assisted, history/methods; Magnetic Resonance Imaging, history/methods;
	Software, history},
  language = {eng},
  medline-pst = {ppublish},
  owner = {stnava},
  pii = {S1053-8119(12)00038-9},
  pmid = {22248573},
  timestamp = {2013.06.10},
  url = {http://dx.doi.org/10.1016/j.neuroimage.2012.01.021}
}

@ARTICLE{gronenschild2012,
  author = {Gronenschild, Ed H B M and Habets, Petra and Jacobs, Heidi I L and
	Mengelers, Ron and Rozendaal, Nico and van Os, Jim and Marcelis,
	Machteld},
  title = {The effects of {FreeSurfer} version, workstation type, and {Macintosh}
	operating system version on anatomical volume and cortical thickness
	measurements},
  journal = {PLoS One},
  year = {2012},
  volume = {7},
  pages = {e38234},
  number = {6},
  abstract = {FreeSurfer is a popular software package to measure cortical thickness
	and volume of neuroanatomical structures. However, little if any
	is known about measurement reliability across various data processing
	conditions. Using a set of 30 anatomical T1-weighted 3T MRI scans,
	we investigated the effects of data processing variables such as
	FreeSurfer version (v4.3.1, v4.5.0, and v5.0.0), workstation (Macintosh
	and Hewlett-Packard), and Macintosh operating system version (OSX
	10.5 and OSX 10.6). Significant differences were revealed between
	FreeSurfer version v5.0.0 and the two earlier versions. These differences
	were on average 8.8 $\pm$ 6.6% (range 1.3-64.0%) (volume) and 2.8
	$\pm$ 1.3% (1.1-7.7%) (cortical thickness). About a factor two smaller
	differences were detected between Macintosh and Hewlett-Packard workstations
	and between OSX 10.5 and OSX 10.6. The observed differences are similar
	in magnitude as effect sizes reported in accuracy evaluations and
	neurodegenerative studies.The main conclusion is that in the context
	of an ongoing study, users are discouraged to update to a new major
	release of either FreeSurfer or operating system or to switch to
	a different type of workstation without repeating the analysis; results
	thus give a quantitative support to successive recommendations stated
	by FreeSurfer developers over the years. Moreover, in view of the
	large and significant cross-version differences, it is concluded
	that formal assessment of the accuracy of FreeSurfer is desirable.},
  bdsk-url-1 = {http://dx.doi.org/10.1371/journal.pone.0038234},
  date-added = {2013-05-02 16:41:33 +0000},
  date-modified = {2013-05-14 14:16:10 +0000},
  doi = {10.1371/journal.pone.0038234},
  journal-full = {PloS one},
  mesh = {Adolescent; Adult; Cerebral Cortex; Computers; Humans; Magnetic Resonance
	Imaging; Middle Aged; Organ Size; Software; Young Adult},
  pmc = {PMC3365894},
  pmid = {22675527},
  pst = {ppublish}
}

@ARTICLE{haegelen2013,
  author = {Haegelen, Claire and Coup{\'e}, Pierrick and Fonov, Vladimir and
	Guizard, Nicolas and Jannin, Pierre and Morandi, Xavier and Collins,
	D Louis},
  title = {Automated segmentation of basal ganglia and deep brain structures
	in {MRI} of {P}arkinson's disease},
  journal = {Int J Comput Assist Radiol Surg},
  year = {2013},
  volume = {8},
  pages = {99-110},
  number = {1},
  month = {Jan},
  abstract = {PURPOSE: Template-based segmentation techniques have been developed
	to facilitate the accurate targeting of deep brain structures in
	patients with movement disorders. Three template-based brain MRI
	segmentation techniques were compared to determine the best strategy
	for segmenting the deep brain structures of patients with Parkinson's
	disease. METHODS: T1-weighted and T2-weighted magnetic resonance
	(MR) image templates were created by averaging MR images of 57 patients
	with Parkinson's disease. Twenty-four deep brain structures were
	manually segmented on the templates. To validate the template-based
	segmentation, 14 of the 24 deep brain structures from the templates
	were manually segmented on 10 MR scans of Parkinson's patients as
	a gold standard. We compared the manual segmentations with three
	methods of automated segmentation: two registration-based approaches,
	automatic nonlinear image matching and anatomical labeling (ANIMAL)
	and symmetric image normalization (SyN), and one patch-label fusion
	technique. The automated labels were then compared with the manual
	labels using a Dice-kappa metric and center of gravity. A Friedman
	test was used to compare the Dice-kappa values and paired t tests
	for the center of gravity. RESULTS: The Friedman test showed a significant
	difference between the three methods for both thalami (p < 0.05)
	and not for the subthalamic nuclei. Registration with ANIMAL was
	better than with SyN for the left thalamus and was better than the
	patch-based method for the right thalamus. CONCLUSION: Although template-based
	approaches are the most used techniques to segment basal ganglia
	by warping onto MR images, we found that the patch-based method provided
	similar results and was less time-consuming. Patch-based method may
	be preferable for the subthalamic nucleus segmentation in patients
	with Parkinson's disease.},
  bdsk-url-1 = {http://dx.doi.org/10.1007/s11548-012-0675-8},
  date-added = {2013-05-02 16:41:41 +0000},
  date-modified = {2013-05-14 14:16:37 +0000},
  doi = {10.1007/s11548-012-0675-8},
  journal-full = {International journal of computer assisted radiology and surgery},
  pmid = {22426551},
  pst = {ppublish}
}

@ARTICLE{iglesias2011,
  author = {Iglesias, Juan Eugenio and Liu, Cheng-Yi and Thompson, Paul M and
	Tu, Zhuowen},
  title = {Robust brain extraction across datasets and comparison with publicly
	available methods},
  journal = {IEEE Trans Med Imaging},
  year = {2011},
  volume = {30},
  pages = {1617-34},
  number = {9},
  month = {Sep},
  abstract = {Automatic whole-brain extraction from magnetic resonance images (MRI),
	also known as skull stripping, is a key component in most neuroimage
	pipelines. As the first element in the chain, its robustness is critical
	for the overall performance of the system. Many skull stripping methods
	have been proposed, but the problem is not considered to be completely
	solved yet. Many systems in the literature have good performance
	on certain datasets (mostly the datasets they were trained/tuned
	on), but fail to produce satisfactory results when the acquisition
	conditions or study populations are different. In this paper we introduce
	a robust, learning-based brain extraction system (ROBEX). The method
	combines a discriminative and a generative model to achieve the final
	result. The discriminative model is a Random Forest classifier trained
	to detect the brain boundary; the generative model is a point distribution
	model that ensures that the result is plausible. When a new image
	is presented to the system, the generative model is explored to find
	the contour with highest likelihood according to the discriminative
	model. Because the target shape is in general not perfectly represented
	by the generative model, the contour is refined using graph cuts
	to obtain the final segmentation. Both models were trained using
	92 scans from a proprietary dataset but they achieve a high degree
	of robustness on a variety of other datasets. ROBEX was compared
	with six other popular, publicly available methods (BET, BSE, FreeSurfer,
	AFNI, BridgeBurner, and GCUT) on three publicly available datasets
	(IBSR, LPBA40, and OASIS, 137 scans in total) that include a wide
	range of acquisition hardware and a highly variable population (different
	age groups, healthy/diseased). The results show that ROBEX provides
	significantly improved performance measures for almost every method/dataset
	combination.},
  bdsk-url-1 = {http://dx.doi.org/10.1109/TMI.2011.2138152},
  date-added = {2013-05-28 23:50:40 +0000},
  date-modified = {2013-05-28 23:50:40 +0000},
  doi = {10.1109/TMI.2011.2138152},
  journal-full = {IEEE transactions on medical imaging},
  mesh = {Adult; Aged; Algorithms; Automatic Data Processing; Brain; Computer
	Simulation; Database Management Systems; Databases, Factual; Discriminant
	Analysis; Female; Humans; Image Processing, Computer-Assisted; Magnetic
	Resonance Imaging; Male; Middle Aged; Models, Anatomic; Pattern Recognition,
	Automated; Reproducibility of Results; Sensitivity and Specificity;
	Skull},
  pmid = {21880566},
  pst = {ppublish}
}

@ARTICLE{jenkinson2012,
  author = {Jenkinson, Mark and Beckmann, Christian F and Behrens, Timothy E
	J and Woolrich, Mark W and Smith, Stephen M},
  title = {{FSL}},
  journal = {Neuroimage},
  year = {2012},
  volume = {62},
  pages = {782-90},
  number = {2},
  month = {Aug},
  abstract = {FSL (the FMRIB Software Library) is a comprehensive library of analysis
	tools for functional, structural and diffusion MRI brain imaging
	data, written mainly by members of the Analysis Group, FMRIB, Oxford.
	For this NeuroImage special issue on "20 years of fMRI" we have been
	asked to write about the history, developments and current status
	of FSL. We also include some descriptions of parts of FSL that are
	not well covered in the existing literature. We hope that some of
	this content might be of interest to users of FSL, and also maybe
	to new research groups considering creating, releasing and supporting
	new software packages for brain image analysis.},
  bdsk-url-1 = {http://dx.doi.org/10.1016/j.neuroimage.2011.09.015},
  date-added = {2013-05-06 15:59:24 +0000},
  date-modified = {2013-05-14 14:16:44 +0000},
  doi = {10.1016/j.neuroimage.2011.09.015},
  journal-full = {NeuroImage},
  mesh = {Brain; Brain Mapping; Diffusion Magnetic Resonance Imaging; History,
	20th Century; History, 21st Century; Humans; Image Processing, Computer-Assisted;
	Software},
  pmid = {21979382},
  pst = {ppublish}
}

@ARTICLE{johnson2007,
  author = {Hans J. Johnson and G. Harris and Kent Williams},
  title = {BRAINSFit: Mutual Information Registrations of Whole-Brain 3D Images,
	Using the Insight Toolkit},
  journal = {Insight Journal},
  year = {2007},
  date-added = {2013-05-23 23:37:44 +0000},
  date-modified = {2013-05-23 23:38:59 +0000}
}

@ARTICLE{klauschen2009,
  author = {Klauschen, Frederick and Goldman, Aaron and Barra, Vincent and Meyer-Lindenberg,
	Andreas and Lundervold, Arvid},
  title = {Evaluation of automated brain MR image segmentation and volumetry
	methods},
  journal = {Hum Brain Mapp},
  year = {2009},
  volume = {30},
  pages = {1310-27},
  number = {4},
  month = {Apr},
  abstract = {We compare three widely used brain volumetry methods available in
	the software packages FSL, SPM5, and FreeSurfer and evaluate their
	performance using simulated and real MR brain data sets. We analyze
	the accuracy of gray and white matter volume measurements and their
	robustness against changes of image quality using the BrainWeb MRI
	database. These images are based on "gold-standard" reference brain
	templates. This allows us to assess between- (same data set, different
	method) and also within-segmenter (same method, variation of image
	quality) comparability, for both of which we find pronounced variations
	in segmentation results for gray and white matter volumes. The calculated
	volumes deviate up to >10% from the reference values for gray and
	white matter depending on method and image quality. Sensitivity is
	best for SPM5, volumetric accuracy for gray and white matter was
	similar in SPM5 and FSL and better than in FreeSurfer. FSL showed
	the highest stability for white (<5%), FreeSurfer (6.2%) for gray
	matter for constant image quality BrainWeb data. Between-segmenter
	comparisons show discrepancies of up to >20% for the simulated data
	and 24% on average for the real data sets, whereas within-method
	performance analysis uncovered volume differences of up to >15%.
	Since the discrepancies between results reach the same order of magnitude
	as volume changes observed in disease, these effects limit the usability
	of the segmentation methods for following volume changes in individual
	patients over time and should be taken into account during the planning
	and analysis of brain volume studies.},
  bdsk-url-1 = {http://dx.doi.org/10.1002/hbm.20599},
  date-added = {2013-05-28 23:31:45 +0000},
  date-modified = {2013-05-28 23:31:45 +0000},
  doi = {10.1002/hbm.20599},
  journal-full = {Human brain mapping},
  mesh = {Aged; Algorithms; Automatic Data Processing; Brain; Brain Mapping;
	Computer Simulation; Databases, Bibliographic; Female; Humans; Image
	Processing, Computer-Assisted; Magnetic Resonance Imaging; Male;
	Middle Aged; Reference Values; Software},
  pmid = {18537111},
  pst = {ppublish}
}

@ARTICLE{klein2009,
  author = {Klein, Arno and Andersson, Jesper and Ardekani, Babak A and Ashburner,
	John and Avants, Brian and Chiang, Ming-Chang and Christensen, Gary
	E and Collins, D Louis and Gee, James and Hellier, Pierre and Song,
	Joo Hyun and Jenkinson, Mark and Lepage, Claude and Rueckert, Daniel
	and Thompson, Paul and Vercauteren, Tom and Woods, Roger P and Mann,
	J John and Parsey, Ramin V},
  title = {Evaluation of 14 nonlinear deformation algorithms applied to human
	brain {MRI} registration},
  journal = {Neuroimage},
  year = {2009},
  volume = {46},
  pages = {786-802},
  number = {3},
  month = {Jul},
  abstract = {All fields of neuroscience that employ brain imaging need to communicate
	their results with reference to anatomical regions. In particular,
	comparative morphometry and group analysis of functional and physiological
	data require coregistration of brains to establish correspondences
	across brain structures. It is well established that linear registration
	of one brain to another is inadequate for aligning brain structures,
	so numerous algorithms have emerged to nonlinearly register brains
	to one another. This study is the largest evaluation of nonlinear
	deformation algorithms applied to brain image registration ever conducted.
	Fourteen algorithms from laboratories around the world are evaluated
	using 8 different error measures. More than 45,000 registrations
	between 80 manually labeled brains were performed by algorithms including:
	AIR, ANIMAL, ART, Diffeomorphic Demons, FNIRT, IRTK, JRD-fluid, ROMEO,
	SICLE, SyN, and four different SPM5 algorithms ("SPM2-type" and regular
	Normalization, Unified Segmentation, and the DARTEL Toolbox). All
	of these registrations were preceded by linear registration between
	the same image pairs using FLIRT. One of the most significant findings
	of this study is that the relative performances of the registration
	methods under comparison appear to be little affected by the choice
	of subject population, labeling protocol, and type of overlap measure.
	This is important because it suggests that the findings are generalizable
	to new subject populations that are labeled or evaluated using different
	labeling protocols. Furthermore, we ranked the 14 methods according
	to three completely independent analyses (permutation tests, one-way
	ANOVA tests, and indifference-zone ranking) and derived three almost
	identical top rankings of the methods. ART, SyN, IRTK, and SPM's
	DARTEL Toolbox gave the best results according to overlap and distance
	measures, with ART and SyN delivering the most consistently high
	accuracy across subjects and label sets. Updates will be published
	on the http://www.mindboggle.info/papers/ website.},
  bdsk-url-1 = {http://dx.doi.org/10.1016/j.neuroimage.2008.12.037},
  date-added = {2013-05-10 16:36:22 +0000},
  date-modified = {2013-05-14 14:16:53 +0000},
  doi = {10.1016/j.neuroimage.2008.12.037},
  journal-full = {NeuroImage},
  mesh = {Adult; Algorithms; Artificial Intelligence; Brain; Female; Humans;
	Image Enhancement; Image Interpretation, Computer-Assisted; Magnetic
	Resonance Imaging; Male; Nonlinear Dynamics; Pattern Recognition,
	Automated; Reproducibility of Results; Sensitivity and Specificity;
	Subtraction Technique},
  pmc = {PMC2747506},
  pmid = {19195496},
  pst = {ppublish}
}

@ARTICLE{klein2010,
  author = {Klein, Stefan and Staring, Marius and Murphy, Keelin and Viergever,
	Max A and Pluim, Josien P W},
  title = {{elastix}: a toolbox for intensity-based medical image registration},
  journal = {IEEE Trans Med Imaging},
  year = {2010},
  volume = {29},
  pages = {196-205},
  number = {1},
  month = {Jan},
  abstract = {Medical image registration is an important task in medical image
	processing. It refers to the process of aligning data sets, possibly
	from different modalities (e.g., magnetic resonance and computed
	tomography), different time points (e.g., follow-up scans), and/or
	different subjects (in case of population studies). A large number
	of methods for image registration are described in the literature.
	Unfortunately, there is not one method that works for all applications.
	We have therefore developed elastix, a publicly available computer
	program for intensity-based medical image registration. The software
	consists of a collection of algorithms that are commonly used to
	solve medical image registration problems. The modular design of
	elastix allows the user to quickly configure, test, and compare different
	registration methods for a specific application. The command-line
	interface enables automated processing of large numbers of data sets,
	by means of scripting. The usage of elastix for comparing different
	registration methods is illustrated with three example experiments,
	in which individual components of the registration method are varied.},
  bdsk-url-1 = {http://dx.doi.org/10.1109/TMI.2009.2035616},
  date-added = {2013-05-11 02:52:43 +0000},
  date-modified = {2013-05-14 14:17:00 +0000},
  doi = {10.1109/TMI.2009.2035616},
  journal-full = {IEEE transactions on medical imaging},
  mesh = {Diagnostic Imaging; Humans; Image Processing, Computer-Assisted;
	Models, Biological; Normal Distribution; Software},
  pmid = {19923044},
  pst = {ppublish}
}

@ARTICLE{kovacevic2006,
  author = {Jelena Kovacevic},
  title = {From the editor in chief},
  journal = {IEEE Trans. Image Process.},
  year = {2006},
  volume = {15},
  pages = {12},
  date-added = {2013-05-02 17:42:25 +0000},
  date-modified = {2013-05-02 17:43:09 +0000}
}

@ARTICLE{kriegeskorte2010,
  author = {Kriegeskorte, Nikolaus and Lindquist, Martin A and Nichols, Thomas
	E and Poldrack, Russell A and Vul, Edward},
  title = {Everything you never wanted to know about circular analysis, but
	were afraid to ask},
  journal = {J Cereb Blood Flow Metab},
  year = {2010},
  volume = {30},
  pages = {1551-7},
  number = {9},
  month = {Sep},
  abstract = {Over the past year, a heated discussion about 'circular' or 'nonindependent'
	analysis in brain imaging has emerged in the literature. An analysis
	is circular (or nonindependent) if it is based on data that were
	selected for showing the effect of interest or a related effect.
	The authors of this paper are researchers who have contributed to
	the discussion and span a range of viewpoints. To clarify points
	of agreement and disagreement in the community, we collaboratively
	assembled a series of questions on circularity herein, to which we
	provide our individual current answers in <or=100 words per question.
	Although divergent views remain on some of the questions, there is
	also a substantial convergence of opinion, which we have summarized
	in a consensus box. The box provides the best current answers that
	the five authors could agree upon.},
  bdsk-url-1 = {http://dx.doi.org/10.1038/jcbfm.2010.86},
  date-added = {2013-05-05 18:11:49 +0000},
  date-modified = {2013-05-05 18:11:49 +0000},
  doi = {10.1038/jcbfm.2010.86},
  journal-full = {Journal of cerebral blood flow and metabolism : official journal
	of the International Society of Cerebral Blood Flow and Metabolism},
  mesh = {Brain; Brain Mapping; Data Interpretation, Statistical; Guidelines
	as Topic; Image Processing, Computer-Assisted; Neurosciences; Publications;
	Research Design; Selection Bias},
  pmc = {PMC2949251},
  pmid = {20571517},
  pst = {ppublish}
}

@ARTICLE{kriegeskorte2009,
  author = {Kriegeskorte, Nikolaus and Simmons, W Kyle and Bellgowan, Patrick
	S F and Baker, Chris I},
  title = {Circular analysis in systems neuroscience: the dangers of double
	dipping},
  journal = {Nat Neurosci},
  year = {2009},
  volume = {12},
  pages = {535-40},
  number = {5},
  month = {May},
  abstract = {A neuroscientific experiment typically generates a large amount of
	data, of which only a small fraction is analyzed in detail and presented
	in a publication. However, selection among noisy measurements can
	render circular an otherwise appropriate analysis and invalidate
	results. Here we argue that systems neuroscience needs to adjust
	some widespread practices to avoid the circularity that can arise
	from selection. In particular, 'double dipping', the use of the same
	dataset for selection and selective analysis, will give distorted
	descriptive statistics and invalid statistical inference whenever
	the results statistics are not inherently independent of the selection
	criteria under the null hypothesis. To demonstrate the problem, we
	apply widely used analyses to noise data known to not contain the
	experimental effects in question. Spurious effects can appear in
	the context of both univariate activation analysis and multivariate
	pattern-information analysis. We suggest a policy for avoiding circularity.},
  bdsk-url-1 = {http://dx.doi.org/10.1038/nn.2303},
  date-added = {2013-05-06 18:16:36 +0000},
  date-modified = {2013-05-06 18:16:36 +0000},
  doi = {10.1038/nn.2303},
  journal-full = {Nature neuroscience},
  mesh = {Animals; Artifacts; Data Collection; Data Interpretation, Statistical;
	Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging;
	Neurosciences; Reproducibility of Results; Selection Bias; Systems
	Biology},
  pmc = {PMC2841687},
  pmid = {19396166},
  pst = {ppublish}
}

@ARTICLE{luo2013,
  author = {Luo, Yishan and Chung, Albert C S},
  title = {Nonrigid image registration with crystal dislocation energy},
  journal = {IEEE Trans Image Process},
  year = {2013},
  volume = {22},
  pages = {229-43},
  number = {1},
  month = {Jan},
  abstract = {The goal of nonrigid image registration is to find a suitable transformation
	such that the transformed moving image becomes similar to the reference
	image. The image registration problem can also be treated as an optimization
	problem, which tries to minimize an objective energy function that
	measures the differences between two involved images. In this paper,
	we consider image matching as the process of aligning object boundaries
	in two different images. The registration energy function can be
	defined based on the total energy associated with the object boundaries.
	The optimal transformation is obtained by finding the equilibrium
	state when the total energy is minimized, which indicates the object
	boundaries find their correspondences and stop deforming. We make
	an analogy between the above processes with the dislocation system
	in physics. The object boundaries are viewed as dislocations (line
	defects) in crystal. Then the well-developed dislocation energy is
	used to derive the energy assigned to object boundaries in images.
	The newly derived registration energy function takes the global gradient
	information of the entire image into consideration, and produces
	an orientation-dependent and long-range interaction between two images
	to drive the registration process. This property of interaction endows
	the new registration framework with both fast convergence rate and
	high registration accuracy. Moreover, the new energy function can
	be adapted to realize symmetric diffeomorphic transformation so as
	to ensure one-to-one matching between subjects. In this paper, the
	superiority of the new method is theoretically proven, experimentally
	tested and compared with the state-of-the-art SyN method. Experimental
	results with 3-D magnetic resonance brain images demonstrate that
	the proposed method outperforms the compared methods in terms of
	both registration accuracy and computation time.},
  bdsk-url-1 = {http://dx.doi.org/10.1109/TIP.2012.2205005},
  date-added = {2013-05-11 12:34:46 +0000},
  date-modified = {2013-05-11 12:34:46 +0000},
  doi = {10.1109/TIP.2012.2205005},
  journal-full = {IEEE transactions on image processing : a publication of the IEEE
	Signal Processing Society},
  pmid = {22736644},
  pst = {ppublish}
}

@ARTICLE{Merali2010,
  author = {Merali, Zeeya},
  title = {Computational science: ...Error.},
  journal = {Nature},
  year = {2010},
  volume = {467},
  pages = {775--777},
  number = {7317},
  month = {Oct},
  doi = {10.1038/467775a},
  keywords = {Access to Information; Computer Literacy; Research Design; Research
	Personnel, education; Retraction of Publication as Topic; Software,
	standards},
  language = {eng},
  medline-pst = {ppublish},
  owner = {stnava},
  pii = {467775a},
  pmid = {20944712},
  timestamp = {2013.06.10},
  url = {http://dx.doi.org/10.1038/467775a}
}

@ARTICLE{Murphy2011,
  author = {Murphy, Keelin and {van Ginneken}, Bram and Reinhardt, Joseph M.
	and Kabus, Sven and Ding, Kai and Deng, Xiang and Cao, Kunlin and
	Du, Kaifang and Christensen, Gary E. and Garcia, Vincent and Vercauteren,
	Tom and Ayache, Nicholas and Commowick, Olivier and Malandain, Grégoire
	and Glocker, Ben and Paragios, Nikos and Navab, Nassir and Gorbunova,
	Vladlena and Sporring, Jon and {de Bruijne}, Marleen and Han, Xiao
	and Heinrich, Mattias P. and Schnabel, Julia A. and Jenkinson, Mark
	and Lorenz, Cristian and Modat, Marc and McClelland, Jamie R. and
	Ourselin, Sébastien and Muenzing, Sascha E A. and Viergever, Max
	A. and {De Nigris}, Dante and Collins, D Louis and Arbel, Tal and
	Peroni, Marta and Li, Rui and Sharp, Gregory C. and Schmidt-Richberg,
	Alexander and Ehrhardt, Jan and Werner, René and Smeets, Dirk and
	Loeckx, Dirk and Song, Gang and Tustison, Nicholas and Avants, Brian
	and Gee, James C. and Staring, Marius and Klein, Stefan and Stoel,
	Berend C. and Urschler, Martin and Werlberger, Manuel and Vandemeulebroucke,
	Jef and Rit, Simon and Sarrut, David and Pluim, Josien P W.},
  title = {Evaluation of registration methods on thoracic CT: the EMPIRE10 challenge.},
  journal = {IEEE Trans Med Imaging},
  year = {2011},
  volume = {30},
  pages = {1901--1920},
  number = {11},
  month = {Nov},
  abstract = {EMPIRE10 (Evaluation of Methods for Pulmonary Image REgistration
	2010) is a public platform for fair and meaningful comparison of
	registration algorithms which are applied to a database of intrapatient
	thoracic CT image pairs. Evaluation of nonrigid registration techniques
	is a nontrivial task. This is compounded by the fact that researchers
	typically test only on their own data, which varies widely. For this
	reason, reliable assessment and comparison of different registration
	algorithms has been virtually impossible in the past. In this work
	we present the results of the launch phase of EMPIRE10, which comprised
	the comprehensive evaluation and comparison of 20 individual algorithms
	from leading academic and industrial research groups. All algorithms
	are applied to the same set of 30 thoracic CT pairs. Algorithm settings
	and parameters are chosen by researchers expert in the configuration
	of their own method and the evaluation is independent, using the
	same criteria for all participants. All results are published on
	the EMPIRE10 website (http://empire10.isi.uu.nl). The challenge remains
	ongoing and open to new participants. Full results from 24 algorithms
	have been published at the time of writing. This paper details the
	organization of the challenge, the data and evaluation methods and
	the outcome of the initial launch with 20 algorithms. The gain in
	knowledge and future work are discussed.},
  doi = {10.1109/TMI.2011.2158349},
  institution = {Image Sciences Institute, University Medical Center, Utrecht, The
	Netherlands.},
  keywords = {Algorithms; Animals; Databases, Factual; Lung, radiography; Observer
	Variation; Radiographic Image Enhancement; Radiographic Image Interpretation,
	Computer-Assisted, methods; Radiography, Thoracic, methods; Reference
	Standards; Reproducibility of Results; Sensitivity and Specificity;
	Sheep; Software Validation; Thorax; Tomography, X-Ray Computed, methods},
  language = {eng},
  medline-pst = {ppublish},
  owner = {stnava},
  pmid = {21632295},
  timestamp = {2013.06.10},
  url = {http://dx.doi.org/10.1109/TMI.2011.2158349}
}

@ARTICLE{poldrack2008,
  author = {Poldrack, Russell A and Fletcher, Paul C and Henson, Richard N and
	Worsley, Keith J and Brett, Matthew and Nichols, Thomas E},
  title = {Guidelines for reporting an {fMRI} study},
  journal = {Neuroimage},
  year = {2008},
  volume = {40},
  pages = {409-14},
  number = {2},
  month = {Apr},
  abstract = {In this editorial, we outline a set of guidelines for the reporting
	of methods and results in functional magnetic resonance imaging studies
	and provide a checklist to assist authors in preparing manuscripts
	that meet these guidelines.},
  bdsk-url-1 = {http://dx.doi.org/10.1016/j.neuroimage.2007.11.048},
  date-added = {2013-05-05 18:11:24 +0000},
  date-modified = {2013-05-14 14:17:11 +0000},
  doi = {10.1016/j.neuroimage.2007.11.048},
  journal-full = {NeuroImage},
  mesh = {Guidelines as Topic; Magnetic Resonance Imaging; Publishing},
  pmc = {PMC2287206},
  pmid = {18191585},
  pst = {ppublish}
}

@ARTICLE{Prlic2012,
  author = {Prli?, Andreas and Procter, James B.},
  title = {Ten simple rules for the open development of scientific software.},
  journal = {PLoS Comput Biol},
  year = {2012},
  volume = {8},
  pages = {e1002802},
  number = {12},
  __markedentry = {[stnava:]},
  doi = {10.1371/journal.pcbi.1002802},
  keywords = {Guidelines as Topic; Software},
  language = {eng},
  medline-pst = {ppublish},
  owner = {stnava},
  pii = {PCOMPBIOL-D-12-01659},
  pmid = {23236269},
  timestamp = {2013.06.10},
  url = {http://dx.doi.org/10.1371/journal.pcbi.1002802}
}

@ARTICLE{rohlfing2012,
  author = {Rohlfing, Torsten},
  title = {Image similarity and tissue overlaps as surrogates for image registration
	accuracy: widely used but unreliable},
  journal = {IEEE Trans Med Imaging},
  year = {2012},
  volume = {31},
  pages = {153-63},
  number = {2},
  month = {Feb},
  abstract = {The accuracy of nonrigid image registrations is commonly approximated
	using surrogate measures such as tissue label overlap scores, image
	similarity, image difference, or transformation inverse consistency
	error. This paper provides experimental evidence that these measures,
	even when used in combination, cannot distinguish accurate from inaccurate
	registrations. To this end, we introduce a "registration" algorithm
	that generates highly inaccurate image transformations, yet performs
	extremely well in terms of the surrogate measures. Of the tested
	criteria, only overlap scores of localized anatomical regions reliably
	distinguish reasonable from inaccurate registrations, whereas image
	similarity and tissue overlap do not. We conclude that tissue overlap
	and image similarity, whether used alone or together, do not provide
	valid evidence for accurate registrations and should thus not be
	reported or accepted as such.},
  bdsk-url-1 = {http://dx.doi.org/10.1109/TMI.2011.2163944},
  date-added = {2013-05-11 17:25:03 +0000},
  date-modified = {2013-05-11 17:25:03 +0000},
  doi = {10.1109/TMI.2011.2163944},
  journal-full = {IEEE transactions on medical imaging},
  mesh = {Algorithms; Biological Markers; Brain; Humans; Image Enhancement;
	Image Interpretation, Computer-Assisted; Magnetic Resonance Imaging;
	Pattern Recognition, Automated; Reproducibility of Results; Sensitivity
	and Specificity; Subtraction Technique},
  pmc = {PMC3274625},
  pmid = {21827972},
  pst = {ppublish}
}

@ARTICLE{saad2012,
  author = {Saad, Ziad S and Reynolds, Richard C},
  title = {SUMA},
  journal = {Neuroimage},
  year = {2012},
  volume = {62},
  pages = {768-73},
  number = {2},
  month = {Aug},
  abstract = {Surface-based brain imaging analysis offers the advantages of preserving
	the topology of cortical activation, increasing statistical power
	of group-level statistics, estimating cortical thickness, and visualizing
	with ease the pattern of activation across the whole cortex. SUMA
	is an open-source suite of programs for performing surface-based
	analysis and visualization. It was designed since its inception to
	allow for a fine control over the mapping between volume and surface
	domains, and for very fast and simultaneous display of multiple surface
	models and corresponding multitudes of datasets, all while maintaining
	a direct two-way link to volumetric data from which surface models
	and data originated. SUMA provides tools for performing spatial operations
	such as controlled smoothing, clustering, and interactive ROI drawing
	on folded surfaces in 3D, in addition to the various level-1 and
	level-2 FMRI statistics including FDR and FWE correction for multiple
	comparisons. In our contribution to this commemorative issue of Neuroimage
	we touch on the importance of surface-based analysis and provide
	a historic backdrop that motivated the creation of SUMA. We also
	highlight features that are particular to SUMA, notably the standardization
	procedure of meshes to greatly facilitate group-level analyses, and
	the ability to control SUMA's graphical interface from external programs
	making it possible to handle large collections of data with relative
	ease.},
  bdsk-url-1 = {http://dx.doi.org/10.1016/j.neuroimage.2011.09.016},
  date-added = {2013-05-06 16:00:41 +0000},
  date-modified = {2013-05-06 16:00:41 +0000},
  doi = {10.1016/j.neuroimage.2011.09.016},
  journal-full = {NeuroImage},
  mesh = {Brain Mapping; Cerebral Cortex; History, 20th Century; History, 21st
	Century; Humans; Image Processing, Computer-Assisted; Imaging, Three-Dimensional;
	Magnetic Resonance Imaging; Software},
  pmc = {PMC3260385},
  pmid = {21945692},
  pst = {ppublish}
}

@ARTICLE{sackett1979,
  author = {Sackett, D L},
  title = {Bias in analytic research},
  journal = {J Chronic Dis},
  year = {1979},
  volume = {32},
  pages = {51-63},
  number = {1-2},
  date-added = {2013-05-05 18:14:04 +0000},
  date-modified = {2013-05-05 18:14:04 +0000},
  journal-full = {Journal of chronic diseases},
  mesh = {Epidemiologic Methods; Research Design; Retrospective Studies; Sampling
	Studies; Statistics as Topic; Terminology as Topic},
  pmid = {447779},
  pst = {ppublish}
}

@ARTICLE{shattuck2009,
  author = {Shattuck, David W and Prasad, Gautam and Mirza, Mubeena and Narr,
	Katherine L and Toga, Arthur W},
  title = {Online resource for validation of brain segmentation methods},
  journal = {Neuroimage},
  year = {2009},
  volume = {45},
  pages = {431-9},
  number = {2},
  month = {Apr},
  abstract = {One key issue that must be addressed during the development of image
	segmentation algorithms is the accuracy of the results they produce.
	Algorithm developers require this so they can see where methods need
	to be improved and see how new developments compare with existing
	ones. Users of algorithms also need to understand the characteristics
	of algorithms when they select and apply them to their neuroimaging
	analysis applications. Many metrics have been proposed to characterize
	error and success rates in segmentation, and several datasets have
	also been made public for evaluation. Still, the methodologies used
	in analyzing and reporting these results vary from study to study,
	so even when studies use the same metrics their numerical results
	may not necessarily be directly comparable. To address this problem,
	we developed a web-based resource for evaluating the performance
	of skull-stripping in T1-weighted MRI. The resource provides both
	the data to be segmented and an online application that performs
	a validation study on the data. Users may download the test dataset,
	segment it using whichever method they wish to assess, and upload
	their segmentation results to the server. The server computes a series
	of metrics, displays a detailed report of the validation results,
	and archives these for future browsing and analysis. We applied this
	framework to the evaluation of 3 popular skull-stripping algorithms--the
	Brain Extraction Tool [Smith, S.M., 2002. Fast robust automated brain
	extraction. Hum. Brain Mapp. 17 (3),143-155 (Nov)], the Hybrid Watershed
	Algorithm [S{\'e}gonne, F., Dale, A.M., Busa, E., Glessner, M., Salat,
	D., Hahn, H.K., Fischl, B., 2004. A hybrid approach to the skull
	stripping problem in MRI. NeuroImage 22 (3), 1060-1075 (Jul)], and
	the Brain Surface Extractor [Shattuck, D.W., Sandor-Leahy, S.R.,
	Schaper, K.A., Rottenberg, D.A., Leahy, R.M., 2001. Magnetic resonance
	image tissue classification using a partial volume model. NeuroImage
	13 (5), 856-876 (May) under several different program settings. Our
	results show that with proper parameter selection, all 3 algorithms
	can achieve satisfactory skull-stripping on the test data.},
  bdsk-url-1 = {http://dx.doi.org/10.1016/j.neuroimage.2008.10.066},
  date-added = {2013-05-29 00:16:35 +0000},
  date-modified = {2013-05-29 00:16:35 +0000},
  doi = {10.1016/j.neuroimage.2008.10.066},
  journal-full = {NeuroImage},
  mesh = {Adult; Algorithms; Computer Simulation; Database Management Systems;
	Databases, Factual; Female; Humans; Image Enhancement; Image Interpretation,
	Computer-Assisted; Information Dissemination; Internet; Magnetic
	Resonance Imaging; Male; Models, Anatomic; Pattern Recognition, Automated;
	Reproducibility of Results; Sensitivity and Specificity},
  pmc = {PMC2757629},
  pmid = {19073267},
  pst = {ppublish}
}

@ARTICLE{tustison2012a,
  author = {Nicholas J. Tustison and Brian B. Avants},
  title = {The TVDMFFDVR Algorithm},
  journal = {Insight Journal},
  year = {2012},
  date-added = {2013-05-23 23:46:22 +0000},
  date-modified = {2013-05-23 23:47:24 +0000}
}

@ARTICLE{tustison2012,
  author = {Tustison, Nicholas J and Avants, Brian B and Cook, Philip A and Kim,
	Junghoon and Whyte, John and Gee, James C and Stone, James R},
  title = {Logical circularity in voxel-based analysis: Normalization strategy
	may induce statistical bias},
  journal = {Hum Brain Mapp},
  year = {2012},
  month = {Nov},
  abstract = {Recent discussions within the neuroimaging community have highlighted
	the problematic presence of selection bias in experimental design.
	Although initially centering on the selection of voxels during the
	course of fMRI studies, we demonstrate how this bias can potentially
	corrupt voxel-based analyses. For such studies, template-based registration
	plays a critical role in which a representative template serves as
	the normalized space for group alignment. A standard approach maps
	each subject's image to a representative template before performing
	statistical comparisons between different groups. We analytically
	demonstrate that in these scenarios the popular sum of squared difference
	(SSD) intensity metric, implicitly surrogating as a quantification
	of anatomical alignment, instead explicitly maximizes effect size-an
	experimental design flaw referred to as "circularity bias." We illustrate
	how this selection bias varies in strength with the similarity metric
	used during registration under the hypothesis that while SSD-related
	metrics, such as Demons, will manifest similar effects, other metrics
	which are not formulated based on absolute intensity differences
	will produce less of an effect. Consequently, given the variability
	in voxel-based analysis outcomes with similarity metric choice, we
	caution researchers specifically in the use of SSD and SSD-related
	measures where normalization and statistical analysis involve the
	same image set. Instead, we advocate a more cautious approach where
	normalization of the individual subject images to the reference space
	occurs through corresponding image sets which are independent of
	statistical testing. Alternatively, one can use similarity terms
	that are less sensitive to this bias. Hum Brain Mapp, 2012. {\copyright}
	2012 Wiley Periodicals, Inc.},
  bdsk-url-1 = {http://dx.doi.org/10.1002/hbm.22211},
  date-added = {2013-05-05 18:12:13 +0000},
  date-modified = {2013-05-05 18:12:13 +0000},
  doi = {10.1002/hbm.22211},
  journal-full = {Human brain mapping},
  pmid = {23151955},
  pst = {aheadofprint}
}

@ARTICLE{tustison2010,
  author = {Tustison, Nicholas J and Avants, Brian B and Cook, Philip A and Zheng,
	Yuanjie and Egan, Alexander and Yushkevich, Paul A and Gee, James
	C},
  title = {N4ITK: improved N3 bias correction},
  journal = {IEEE Trans Med Imaging},
  year = {2010},
  volume = {29},
  pages = {1310-20},
  number = {6},
  month = {Jun},
  abstract = {A variant of the popular nonparametric nonuniform intensity normalization
	(N3) algorithm is proposed for bias field correction. Given the superb
	performance of N3 and its public availability, it has been the subject
	of several evaluation studies. These studies have demonstrated the
	importance of certain parameters associated with the B-spline least-squares
	fitting. We propose the substitution of a recently developed fast
	and robust B-spline approximation routine and a modified hierarchical
	optimization scheme for improved bias field correction over the original
	N3 algorithm. Similar to the N3 algorithm, we also make the source
	code, testing, and technical documentation of our contribution, which
	we denote as "N4ITK," available to the public through the Insight
	Toolkit of the National Institutes of Health. Performance assessment
	is demonstrated using simulated data from the publicly available
	Brainweb database, hyperpolarized (3)He lung image data, and 9.4T
	postmortem hippocampus data.},
  bdsk-url-1 = {http://dx.doi.org/10.1109/TMI.2010.2046908},
  date-added = {2013-05-11 11:46:09 +0000},
  date-modified = {2013-05-11 11:46:09 +0000},
  doi = {10.1109/TMI.2010.2046908},
  journal-full = {IEEE transactions on medical imaging},
  mesh = {Algorithms; Artifacts; Brain; Humans; Image Enhancement; Image Interpretation,
	Computer-Assisted; Magnetic Resonance Imaging; Reproducibility of
	Results; Sensitivity and Specificity},
  pmc = {PMC3071855},
  pmid = {20378467},
  pst = {ppublish}
}

@TECHREPORT{tustison2009,
  author = {Nicholas J. Tustison and James C. Gee},
  title = {Introducing {D}ice, {J}accard, and Other Label Overlap Measures To
	{ITK}},
  institution = {PICSL, University of Pennsylvania},
  year = {2009},
  address = {http://www.insight-journal.org/browse/publication/707},
  date-added = {2013-05-10 14:40:00 +0000},
  date-modified = {2013-05-14 14:14:33 +0000},
  journal = {Insight Journal}
}

@TECHREPORT{tustison2009a,
  author = {N. J. Tustison and J. C. Gee},
  title = {{N4ITK}: {N}ick's {N3} {ITK} Implementation For {MRI} Bias Field
	Correction},
  institution = {University of Pennsylvania},
  year = {2009},
  address = {http://www.insight-journal.org/browse/publication/640},
  date-added = {2013-05-11 11:46:28 +0000},
  date-modified = {2013-05-14 14:14:57 +0000}
}

@ARTICLE{van-essen2012,
  author = {Van Essen, David C},
  title = {Cortical cartography and Caret software},
  journal = {Neuroimage},
  year = {2012},
  volume = {62},
  pages = {757-64},
  number = {2},
  month = {Aug},
  abstract = {Caret software is widely used for analyzing and visualizing many
	types of fMRI data, often in conjunction with experimental data from
	other modalities. This article places Caret's development in a historical
	context that spans three decades of brain mapping--from the early
	days of manually generated flat maps to the nascent field of human
	connectomics. It also highlights some of Caret's distinctive capabilities.
	This includes the ease of visualizing data on surfaces and/or volumes
	and on atlases as well as individual subjects. Caret can display
	many types of experimental data using various combinations of overlays
	(e.g., fMRI activation maps, cortical parcellations, areal boundaries),
	and it has other features that facilitate the analysis and visualization
	of complex neuroimaging datasets.},
  bdsk-url-1 = {http://dx.doi.org/10.1016/j.neuroimage.2011.10.077},
  date-added = {2013-05-06 16:01:33 +0000},
  date-modified = {2013-05-06 16:01:33 +0000},
  doi = {10.1016/j.neuroimage.2011.10.077},
  journal-full = {NeuroImage},
  mesh = {Animals; Brain Mapping; Cerebral Cortex; History, 20th Century; History,
	21st Century; Humans; Image Processing, Computer-Assisted; Magnetic
	Resonance Imaging; Software},
  pmc = {PMC3288593},
  pmid = {22062192},
  pst = {ppublish}
}

@ARTICLE{vul2012,
  author = {Vul, Edward and Pashler, Hal},
  title = {Voodoo and circularity errors},
  journal = {Neuroimage},
  year = {2012},
  volume = {62},
  pages = {945-8},
  number = {2},
  month = {Aug},
  abstract = {We briefly describe the circularity/non-independence problem, and
	our perception of the impact the ensuing discussion has had on fMRI
	research.},
  bdsk-url-1 = {http://dx.doi.org/10.1016/j.neuroimage.2012.01.027},
  date-added = {2013-05-05 18:12:03 +0000},
  date-modified = {2013-05-05 18:12:03 +0000},
  doi = {10.1016/j.neuroimage.2012.01.027},
  journal-full = {NeuroImage},
  mesh = {Bias (Epidemiology); Brain; Brain Mapping; Humans; Magnetic Resonance
	Imaging},
  pmid = {22270348},
  pst = {ppublish}
}

@BOOK{wasserman1994,
  title = {Social network analysis: methods and applications},
  publisher = {Cambridge University Press},
  year = {1994},
  author = {Wasserman, Stanley and Faust, Katherine},
  volume = {8},
  address = {Cambridge},
  annote = {LDR 01340cam 2200313 a 4500 001 4906238 005 20020828201303.0 008
	940518s1994 enka b 001 0 eng 035 $9(DLC) 94020602 906 $a7$bcbc$corignew$d1$eocip$f19$gy-gencatlg
	955 $apc19 to sa00 05-19-94; SF07 05-19-94; sf06 05-23-94; sf14 05-23-94;
	aa20 5-26-94; CIP ver. pv07 12-22-94 010 $a 94020602 020 $a0521382696
	(hardback) 020 $a0521387078 (pbk.) 040 $aDLC$cDLC$dDLC 050 00 $aHM131$b.W356
	1994 082 00 $a302/.01/1$220 100 1 $aWasserman, Stanley. 245 10 $aSocial
	network analysis :$bmethods and applications /$cStanley Wasserman,
	Katherine Faust. 260 $aCambridge ;$aNew York :$bCambridge University
	Press,$c1994. 300 $axxxi, 825 p. :$bill. ;$c23 cm. 440 0 $aStructural
	analysis in the social sciences ;$v8 504 $aIncludes bibliographical
	references (p. 756-801) and indexes. 650 0 $aSocial networks$xResearch$xMethodology.
	700 1 $aFaust, Katherine. 856 42 $3Publisher description$uhttp://www.loc.gov/catdir/description/cam026/94020602.html
	856 41 $3Table of contents$uhttp://www.loc.gov/catdir/toc/cam026/94020602.html
	991 $bc-GenColl$hHM131$i.W356 1994$p00055023876$tCopy 1$wBOOKS
	
	},
  bdsk-url-1 = {http://www.loc.gov/catdir/description/cam026/94020602.html},
  call-number = {HM131},
  date-added = {2013-06-05 00:40:20 +0000},
  date-modified = {2013-06-05 00:40:20 +0000},
  dewey-call-number = {302/.01/1},
  genre = {Social networks},
  isbn = {0521382696 (hardback)},
  library-id = {94020602},
  url = {http://www.loc.gov/catdir/description/cam026/94020602.html}
}

@ARTICLE{wolpert1997,
  author = {David Wolpert and William G. Macready},
  title = {No free lunch theorems for optimization},
  journal = {IEEE Trans. Evolutionary Computation},
  year = {1997},
  volume = {1},
  pages = {67-82},
  number = {1},
  bdsk-url-1 = {http://dx.doi.org/10.1109/4235.585893},
  date-added = {2013-05-14 23:06:18 +0000},
  date-modified = {2013-05-14 23:06:42 +0000}
}

@ARTICLE{wu2013,
  author = {Wu, Guorong and Kim, Minjeong and Wang, Qian and Shen, Dinggang},
  title = {S-HAMMER: Hierarchical attribute-guided, symmetric diffeomorphic
	registration for MR brain images},
  journal = {Hum Brain Mapp},
  year = {2013},
  month = {Jan},
  abstract = {Deformable registration has been widely used in neuroscience studies
	for spatial normalization of brain images onto the standard space.
	Because of possible large anatomical differences across different
	individual brains, registration performance could be limited when
	trying to estimate a single directed deformation pathway, i.e., either
	from template to subject or from subject to template. Symmetric image
	registration, however, offers an effective way to simultaneously
	deform template and subject images toward each other until they meet
	at the middle point. Although some intensity-based registration algorithms
	have nicely incorporated this concept of symmetric deformation, the
	pointwise intensity matching between two images may not necessarily
	imply the matching of correct anatomical correspondences. Based on
	HAMMER registration algorithm (Shen and Davatzikos, [2002]: IEEE
	Trans Med Imaging 21:1421-1439), we integrate the strategies of hierarchical
	attribute matching and symmetric diffeomorphic deformation to build
	a new symmetric-diffeomorphic HAMMER registration algorithm, called
	as S-HAMMER. The performance of S-HAMMER has been extensively compared
	with 14 state-of-the-art nonrigid registration algorithms evaluated
	in (Klein et al., [2009]: NeuroImage 46:786-802) by using real brain
	images in LPBA40, IBSR18, CUMC12, and MGH10 datasets. In addition,
	the registration performance of S-HAMMER, by comparison with other
	methods, is also demonstrated on both elderly MR brain images (>70
	years old) and the simulated brain images with ground-truth deformation
	fields. In all experiments, our proposed method achieves the best
	registration performance over all other registration methods, indicating
	the high applicability of our method in future neuroscience and clinical
	applications. Hum Brain Mapp, 2012. {\copyright} 2012 Wiley Periodicals,
	Inc.},
  bdsk-url-1 = {http://dx.doi.org/10.1002/hbm.22233},
  date-added = {2013-05-11 12:41:40 +0000},
  date-modified = {2013-05-11 12:41:40 +0000},
  doi = {10.1002/hbm.22233},
  journal-full = {Human brain mapping},
  pmid = {23283836},
  pst = {aheadofprint}
}

@ARTICLE{Yushkevich2010,
  author = {Yushkevich, Paul A. and Avants, Brian B. and Das, Sandhitsu R. and
	Pluta, John and Altinay, Murat and Craige, Caryne and , Alzheimer's
	Disease Neuroimaging Initiative},
  title = {Bias in estimation of hippocampal atrophy using deformation-based
	morphometry arises from asymmetric global normalization: an illustration
	in ADNI 3 T MRI data.},
  journal = {Neuroimage},
  year = {2010},
  volume = {50},
  pages = {434--445},
  number = {2},
  month = {Apr},
  __markedentry = {[stnava:6]},
  abstract = {Measurement of brain change due to neurodegenerative disease and
	treatment is one of the fundamental tasks of neuroimaging. Deformation-based
	morphometry (DBM) has been long recognized as an effective and sensitive
	tool for estimating the change in the volume of brain regions over
	time. This paper demonstrates that a straightforward application
	of DBM to estimate the change in the volume of the hippocampus can
	result in substantial bias, i.e., an overestimation of the rate of
	change in hippocampal volume. In ADNI data, this bias is manifested
	as a non-zero intercept of the regression line fitted to the 6 and
	12 month rates of hippocampal atrophy. The bias is further confirmed
	by applying DBM to repeat scans of subjects acquired on the same
	day. This bias appears to be the result of asymmetry in the interpolation
	of baseline and followup images during longitudinal image registration.
	Correcting this asymmetry leads to bias-free atrophy estimation.},
  institution = {Department of Radiology, University of Pennsylvania, Philadelphia,
	PA 19104, USA. pauly2@mail.med.upenn.edu},
  keywords = {Alzheimer Disease, epidemiology/pathology; Atrophy, pathology; Bias
	(Epidemiology); Brain Mapping, methods; Hippocampus, pathology; Humans;
	Image Interpretation, Computer-Assisted, methods; Magnetic Resonance
	Imaging},
  language = {eng},
  medline-pst = {ppublish},
  owner = {stnava},
  pmid = {20005963},
  timestamp = {2013.06.10}
}

